#!/usr/bin/env bash
RAY_memory_monitor_refresh_ms=0 RAY_memory_usage_threshold=0.8 PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python -m vllm.entrypoints.openai.api_server --model shenzhi-wang/Llama3.1-8B-Chinese-Chat --served-model-name Llama3.1-8B-Chinese-Chat --trust-remote-code --port 8082 --device cuda --tensor-parallel-size 2 --gpu-memory-utilization 0.9 --swap-space 2